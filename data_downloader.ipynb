{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T14:26:21.532142Z",
     "start_time": "2025-04-24T14:26:20.114458Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "from py7zr import unpack_7zarchive\n",
    "import shutil\n",
    "from datasets import Dataset\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eebb5762209aa9ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T08:50:26.412701Z",
     "start_time": "2025-04-15T08:50:26.392732Z"
    }
   },
   "outputs": [],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91a3f015e67c693b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T08:50:27.714394Z",
     "start_time": "2025-04-15T08:50:27.709408Z"
    }
   },
   "outputs": [],
   "source": [
    "download_path = \"./data_raw\"\n",
    "os.makedirs(download_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "109985e984d48227",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T08:51:21.224970Z",
     "start_time": "2025-04-15T08:50:33.375257Z"
    }
   },
   "outputs": [],
   "source": [
    "api.competition_download_file('tensorflow-speech-recognition-challenge', path=download_path, file_name = 'train.7z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7ca1cc459141ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T08:58:23.990850Z",
     "start_time": "2025-04-15T08:53:54.736716Z"
    }
   },
   "outputs": [],
   "source": [
    "shutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)\n",
    "shutil.unpack_archive('./data_raw/train.7z', './data_raw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d19132cd5ba59f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T14:26:24.514150Z",
     "start_time": "2025-04-24T14:26:24.498191Z"
    }
   },
   "outputs": [],
   "source": [
    "final_labels = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'unknown']\n",
    "idname = {i: name for i, name in enumerate(final_labels)}\n",
    "nameid = {name: i for i, name in idname.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4386b362912ee14d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T14:26:27.828611Z",
     "start_time": "2025-04-24T14:26:26.612112Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = './data_raw/train/audio'\n",
    "data = []\n",
    "for folder in os.listdir(data_dir):\n",
    "    folder_path = os.path.join(data_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        label = folder\n",
    "        label_name = label\n",
    "        if label == '_background_noise_':\n",
    "            label_name = 'silence'\n",
    "        elif label not in final_labels:\n",
    "            label_name = 'unknown'\n",
    "        label_id = nameid[label_name]\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".wav\"):\n",
    "                relative_path = os.path.join(label, file_name).replace(\"\\\\\", \"/\")\n",
    "                data.append({\n",
    "                    \"audio_path\": relative_path,\n",
    "                    \"label\": label_name,\n",
    "                    \"label_id\": label_id\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48bea3f59b66ea96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T14:26:30.261989Z",
     "start_time": "2025-04-24T14:26:30.130310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 51492, Validation: 6798, Test: 6835\n"
     ]
    }
   ],
   "source": [
    "def read_list(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        return set(line.strip().replace(\"\\\\\", \"/\") for line in f if line.strip())\n",
    "\n",
    "val_list = read_list(\"./data_raw/train/validation_list.txt\")\n",
    "test_list = read_list(\"./data_raw/train/testing_list.txt\")\n",
    "\n",
    "train_data, val_data, test_data = [], [], []\n",
    "\n",
    "for example in data:\n",
    "    path = example[\"audio_path\"]\n",
    "    if path in val_list:\n",
    "        val_data.append(example)\n",
    "    elif path in test_list:\n",
    "        test_data.append(example)\n",
    "    else:\n",
    "        train_data.append(example)\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Validation: {len(val_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81d7f4e51a3e0732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T14:26:37.326372Z",
     "start_time": "2025-04-24T14:26:37.026416Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir  = \"./data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def save_dataset(dataset, name, output_dir):\n",
    "    df = dataset.to_pandas()\n",
    "    output_path = os.path.join(output_dir, f\"{name}.csv\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "save_dataset(train_dataset, \"train\", output_dir)\n",
    "save_dataset(val_dataset, \"validation\", output_dir)\n",
    "save_dataset(test_dataset, \"test\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e0dd7638e9de81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T14:26:59.677574Z",
     "start_time": "2025-04-24T14:26:39.751553Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dir = './data_raw/train/audio/_background_noise_'\n",
    "output_dir = './data_raw/train/audio/processed_silence'\n",
    "csv_path = './data/silence_dataset.csv'\n",
    "sr = 16000\n",
    "chunk_duration = 1.0 \n",
    "chunk_samples = int(sr * chunk_duration)\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "data = []\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.wav'):\n",
    "        filepath = os.path.join(input_dir, filename)\n",
    "        signal, _ = librosa.load(filepath, sr=sr)\n",
    "\n",
    "        num_chunks = len(signal) // chunk_samples\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "\n",
    "        for i in range(num_chunks):\n",
    "            chunk = signal[i * chunk_samples : (i + 1) * chunk_samples]\n",
    "            out_filename = f\"{base_name}_chunk_{i}.wav\"\n",
    "            out_path = os.path.join(output_dir, out_filename)\n",
    "\n",
    "            sf.write(out_path, chunk, sr)\n",
    "            data.append({\n",
    "                \"audio_path\": f'processed_silence/{out_filename}',\n",
    "                \"label\": 'silence',\n",
    "                \"label_id\": 10\n",
    "            })\n",
    "\n",
    "silence_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628772183d8de4ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T14:27:03.768928Z",
     "start_time": "2025-04-24T14:27:03.489811Z"
    }
   },
   "outputs": [],
   "source": [
    "train_csv = \"./data/train.csv\"\n",
    "val_csv = \"./data/validation.csv\"\n",
    "test_csv = \"./data/test.csv\"\n",
    "\n",
    "silence_df[\"group\"] = silence_df[\"audio_path\"].apply(lambda x: x.split(\"_chunk_\")[0])\n",
    "\n",
    "\n",
    "train_rows, val_rows, test_rows = [], [], []\n",
    "\n",
    "for group, group_df in silence_df.groupby(\"group\"):\n",
    "    group_df = group_df.sample(frac=1, random_state=42)\n",
    "\n",
    "    n = len(group_df)\n",
    "    n_train = int(0.8 * n)\n",
    "    n_val = int(0.1 * n)\n",
    "\n",
    "    train_rows.append(group_df.iloc[:n_train].drop(columns=\"group\"))\n",
    "    val_rows.append(group_df.iloc[n_train:n_train + n_val].drop(columns=\"group\"))\n",
    "    test_rows.append(group_df.iloc[n_train + n_val:].drop(columns=\"group\"))\n",
    "\n",
    "new_train_df = pd.concat(train_rows)\n",
    "new_val_df = pd.concat(val_rows)\n",
    "new_test_df = pd.concat(test_rows)\n",
    "\n",
    "train_df = pd.read_csv(train_csv)\n",
    "val_df = pd.read_csv(val_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "def remove_background_noise(df):\n",
    "    return df[~df[\"audio_path\"].str.startswith(\"_background_noise_\")]\n",
    "\n",
    "train_df = remove_background_noise(train_df)\n",
    "val_df = remove_background_noise(val_df)\n",
    "test_df = remove_background_noise(test_df)\n",
    "\n",
    "train_df = pd.concat([train_df, new_train_df], ignore_index=True)\n",
    "val_df = pd.concat([val_df, new_val_df], ignore_index=True)\n",
    "test_df = pd.concat([test_df, new_test_df], ignore_index=True)\n",
    "\n",
    "train_df.to_csv(train_csv, index=False)\n",
    "val_df.to_csv(val_csv, index=False)\n",
    "test_df.to_csv(test_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f73fb70c94c239f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T14:28:21.380047Z",
     "start_time": "2025-04-24T14:28:21.370073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(silence_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b346d347aad201",
   "metadata": {},
   "source": [
    "### Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9c3ba67b3020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AudioDataset import AudioDataset\n",
    "import torch\n",
    "\n",
    "dataset = AudioDataset(\n",
    "    csv_path=\"./data/train.csv\",\n",
    "    audio_dir=\"./data_raw/train/audio\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce88486caf5a50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for features, labels in dataloader:\n",
    "    print(features.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
